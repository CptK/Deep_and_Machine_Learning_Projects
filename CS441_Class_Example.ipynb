{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CptK/Deep_and_Machine_Learning_Projects/blob/master/CS441_Class_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagOldZDQJvG"
      },
      "source": [
        "### Wisconsin Breast Cancer Dataset Example (CS 441)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vO_W4UH7NNBo",
        "outputId": "0a1b8680-f2ef-4ce6-8a08-b59a7fd480d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ]
        }
      ],
      "source": [
        "# initialization code\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "xnames = data.feature_names\n",
        "ynames = data.target_names\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does my data mean?\n",
        "\n",
        "print('Feature names: {}'.format(xnames))\n",
        "print('Label names: {}'.format(ynames))\n",
        "for i in [0,100,300, 500]:\n",
        "  print('Example {}'.format(i))\n",
        "  print('Features {}'.format(X[i, :]))\n",
        "  print('Prediction {}'.format(y[i]))"
      ],
      "metadata": {
        "id": "jGBoqBKrDX4r",
        "outputId": "6127c73d-1ae6-4bbb-f91c-54e6e2c90e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "Label names: ['malignant' 'benign']\n",
            "Example 0\n",
            "Features [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n",
            "Prediction 0\n",
            "Example 100\n",
            "Features [1.361e+01 2.498e+01 8.805e+01 5.827e+02 9.488e-02 8.511e-02 8.625e-02\n",
            " 4.489e-02 1.609e-01 5.871e-02 4.565e-01 1.290e+00 2.861e+00 4.314e+01\n",
            " 5.872e-03 1.488e-02 2.647e-02 9.921e-03 1.465e-02 2.355e-03 1.699e+01\n",
            " 3.527e+01 1.086e+02 9.065e+02 1.265e-01 1.943e-01 3.169e-01 1.184e-01\n",
            " 2.651e-01 7.397e-02]\n",
            "Prediction 0\n",
            "Example 300\n",
            "Features [1.953e+01 1.890e+01 1.295e+02 1.217e+03 1.150e-01 1.642e-01 2.197e-01\n",
            " 1.062e-01 1.792e-01 6.552e-02 1.111e+00 1.161e+00 7.237e+00 1.330e+02\n",
            " 6.056e-03 3.203e-02 5.638e-02 1.733e-02 1.884e-02 4.787e-03 2.593e+01\n",
            " 2.624e+01 1.711e+02 2.053e+03 1.495e-01 4.116e-01 6.121e-01 1.980e-01\n",
            " 2.968e-01 9.929e-02]\n",
            "Prediction 0\n",
            "Example 500\n",
            "Features [1.504e+01 1.674e+01 9.873e+01 6.894e+02 9.883e-02 1.364e-01 7.721e-02\n",
            " 6.142e-02 1.668e-01 6.869e-02 3.720e-01 8.423e-01 2.304e+00 3.484e+01\n",
            " 4.123e-03 1.819e-02 1.996e-02 1.004e-02 1.055e-02 3.237e-03 1.676e+01\n",
            " 2.043e+01 1.097e+02 8.569e+02 1.135e-01 2.176e-01 1.856e-01 1.018e-01\n",
            " 2.177e-01 8.549e-02]\n",
            "Prediction 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How common is each class?\n",
        "Py0 = np.sum(y==0) / len(y)\n",
        "Py1 = 1 - Py0\n",
        "print('Class prior: P(y=0)={:.2f}, P(y=1)={:.2f}'.format(Py0, Py1))"
      ],
      "metadata": {
        "id": "SXrwwYtJFDw9",
        "outputId": "720199d7-c3f7-4898-c967-853f64405cf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class prior: P(y=0)=0.37, P(y=1)=0.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a training and validation set\n",
        "N_tr = 469\n",
        "\n",
        "np.random.seed(seed=0)\n",
        "ind = np.random.permutation(len(y))\n",
        "X_tr = X[ind[:N_tr], :]\n",
        "y_tr = y[ind[:N_tr]]\n",
        "X_val = X[ind[N_tr:]]\n",
        "y_val = y[ind[N_tr:]]\n",
        "\n",
        "print(X_tr.shape)\n",
        "print(X_val.shape)"
      ],
      "metadata": {
        "id": "wWcTcfhgFIIu",
        "outputId": "b84b7798-0599-4f66-9255-eb22e61d0293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(469, 30)\n",
            "(100, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-Nearest neighbor classifier/regressor\n",
        "def nn(X_tr, y_tr, X_test):\n",
        "  y_test = np.zeros(len(X_test),)\n",
        "  for i in range(len(X_test)):\n",
        "    dist = np.sum((X_tr - X_test[i])**2, axis=1)\n",
        "    j = np.argmin(dist) # use argsort if you need more than one value\n",
        "    y_test[i] = y_tr[j]\n",
        "  return y_test\n",
        "\n",
        "y_pred = nn(X_tr, y_tr, X_val)\n",
        "err = 1-np.mean(y_val==y_pred)\n",
        "print('Err: {:0.4f}'.format(err))"
      ],
      "metadata": {
        "id": "689RL_yvhVBx",
        "outputId": "359ed159-603a-4440-b9c7-35c5ca1f173f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Err: 0.0800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's understand the data a little better\n",
        "for m in range(X_tr.shape[1]):\n",
        "  space = '                       '\n",
        "  space = space[len(xnames[m]):]\n",
        "  print('{}:{}\\tmu={:.2f} std={:0.2f}   mu_0={:.2f}\\tmu_1={:.2f}'.format(xnames[m], space, X_tr[:,m].mean(), X_tr[:,m].std(), X_tr[y_tr==0,m].mean(), X_tr[y_tr==1,m].mean()))"
      ],
      "metadata": {
        "id": "NUt1eBryF2E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize by mean and std\n",
        "X_mu = np.mean(X_tr, axis=0)\n",
        "X_std = np.std(X_tr, axis=0)\n",
        "X_tr_n = (X_tr-X_mu) / X_std\n",
        "X_val_n = (X_val - X_mu) / X_std # note: divide val by same mean and std as train"
      ],
      "metadata": {
        "id": "89hXPOtRjWzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat nearest neighbor on normalized values\n",
        "y_pred = nn(X_tr_n, y_tr, X_val_n)\n",
        "err = 1-np.mean(y_val==y_pred)\n",
        "print('Err: {:0.4f}'.format(err))"
      ],
      "metadata": {
        "id": "NO7tJ2hljx4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes where P(x_i|y) ~ N(mu[i,y], sig[i,y]^2)\n",
        "def nb_gauss_train(X, y, eps):\n",
        "  mu = np.zeros((X.shape[1],2))\n",
        "  sig = np.zeros((X.shape[1],2))\n",
        "  py0 = np.mean(y==0)\n",
        "  for i in range(X.shape[1]):\n",
        "    mu[i, 0] = np.mean(X[y==0, i])\n",
        "    mu[i, 1] = np.mean(X[y==1, i])\n",
        "    sig[i, 0] = np.std(X[y==0, i]) + eps\n",
        "    sig[i, 1] = np.std(X[y==1, i]) + eps\n",
        "  return mu, sig, py0\n",
        "\n",
        "def nb_gauss_predict(X, mu, sig, py0):\n",
        "  log_pxy = np.zeros((len(X),2))\n",
        "  for i in range(X.shape[1]):\n",
        "    log_pxy[:,0] += -(mu[i, 0]-X[:, i])**2 / sig[i, 0]**2\n",
        "    log_pxy[:,1] += -(mu[i, 1]-X[:, i])**2 / sig[i, 1]**2\n",
        "  log_pxy[:,0] += np.log(py0)\n",
        "  log_pxy[:,1] += np.log(1-py0)\n",
        "  pred_y = np.argmax(log_pxy, axis=1)\n",
        "  return pred_y\n",
        "\n",
        "[mu, sig, py0] = nb_gauss_train(X_tr, y_tr, 1/len(X_tr))\n",
        "y_pred = nb_gauss_predict(X_val, mu, sig, py0)\n",
        "err = 1-np.mean(y_val==y_pred)\n",
        "print('Err: {:0.4f}'.format(err))\n",
        "\n",
        "[mu, sig, py0] = nb_gauss_train(X_tr_n, y_tr, 1/len(X_tr))\n",
        "y_pred = nb_gauss_predict(X_val_n, mu, sig, py0)\n",
        "err_n = 1-np.mean(y_val==y_pred)\n",
        "print('Err: {:0.4f} (X is normalized)'.format(err_n))\n",
        "\n",
        "# Why doesn't normalization make any difference here?"
      ],
      "metadata": {
        "id": "RCUZ_g5tj7nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try linear regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(C=1,max_iter=10000).fit(X_tr, y_tr)\n",
        "y_pred = model.predict(X_val)\n",
        "print('LR Err: {:0.4f} (not normalized)'.format(1-np.mean(y_val==y_pred)))\n",
        "\n",
        "model = LogisticRegression(C=1,max_iter=10000).fit(X_tr_n, y_tr)\n",
        "y_pred = model.predict(X_val_n)\n",
        "print('LR Err: {:0.4f} (normalized)'.format(1-np.mean(y_val==y_pred)))"
      ],
      "metadata": {
        "id": "D6A_Bcq7pGgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curve\n",
        "import sklearn.metrics\n",
        "y_conf = model.predict_proba(X_val_n)\n",
        "[fpr, tpr, thresh] = sklearn.metrics.roc_curve(y_val==0, y_conf[:,0])\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n"
      ],
      "metadata": {
        "id": "vAOaN0qluZOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look closer at feature importance\n",
        "model_l2 = LogisticRegression(C=1,max_iter=10000).fit(X_tr_n, y_tr)\n",
        "print(model_l2.coef_)\n",
        "model_l1 = LogisticRegression(C=1,max_iter=10000,penalty=\"l1\",solver=\"liblinear\").fit(X_tr_n, y_tr)\n",
        "y_pred = model.predict(X_val_n)\n",
        "print('LR1 Err: {:0.4f} (normalized)'.format(1-np.mean(y_val==y_pred)))\n",
        "for i in range(X.shape[1]):\n",
        "  space = '                          '\n",
        "  space = space[len(xnames[i]):]\n",
        "  print('{}:{}w_2={:.2f}  w_1={:.2f}'.format(xnames[i], space, model_l2.coef_[0,i], model_l1.coef_[0,i]))\n"
      ],
      "metadata": {
        "id": "1nzV3_0sqmsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tree display\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=0)\n",
        "model.fit(X_tr, y_tr)\n",
        "y_pred = model.predict(X_val)\n",
        "print('Full tree Err: {:0.4f} '.format(1-np.mean(y_val==y_pred)))\n",
        "plt.figure(figsize=(20,20))\n",
        "tree.plot_tree(model, feature_names=xnames)\n",
        "plt.show()\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
        "model.fit(X_tr, y_tr)\n",
        "y_pred = model.predict(X_val)\n",
        "print('Short tree Err: {:0.4f} '.format(1-np.mean(y_val==y_pred)))\n",
        "plt.figure(figsize=(20,20))\n",
        "tree.plot_tree(model, feature_names=xnames)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZBcZPP95ttgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-fold cross-validation experiment for final tests\n",
        "cv_err_nn = np.zeros(10,)\n",
        "cv_err_l1 = np.zeros(10,)\n",
        "np.random.seed(seed=0)\n",
        "rpind = np.random.permutation(len(y))\n",
        "for split in range(10):\n",
        "  \n",
        "  # split into train/val\n",
        "  val_ind = rpind[np.arange(split,len(X), 10)]\n",
        "  X_val = X[val_ind]\n",
        "  y_val = y[val_ind]\n",
        "  tr_ind = np.delete(np.arange(len(X)), val_ind)\n",
        "  X_tr = X[tr_ind]\n",
        "  y_tr = y[tr_ind]\n",
        "\n",
        "  # normalize features based on train mu/std\n",
        "  X_mu = np.mean(X_tr, axis=0)\n",
        "  X_std = np.std(X_tr, axis=0)\n",
        "  X_tr_n = (X_tr-X_mu) / X_std\n",
        "  X_val_n = (X_val - X_mu) / X_std # note: divide val by same mean and std as train\n",
        "\n",
        "  # nn\n",
        "  y_pred = nn(X_tr_n, y_tr, X_val_n)\n",
        "  cv_err_nn[split] = 1-np.mean(y_val==y_pred)\n",
        "\n",
        "  # lr\n",
        "  model = LogisticRegression(C=1,max_iter=10000,penalty=\"l1\",solver=\"liblinear\").fit(X_tr_n, y_tr)\n",
        "  y_pred = model.predict(X_val_n)\n",
        "  cv_err_l1[split] = 1-np.mean(y_val==y_pred)\n",
        "\n",
        "print(cv_err_nn)\n",
        "print(cv_err_l1)\n",
        "print('Nearest Neighbor: mean err={:0.3f}  standard error of mean={:0.3f}  95% confidence interval={:0.3f}'.format(np.mean(cv_err_nn), np.std(cv_err_nn)/np.sqrt(10), np.std(cv_err_nn)/np.sqrt(10)*1.96))\n",
        "print('L1 Logistic Regression: mean err={:0.3f}  standard error of mean={:0.3f}  95% confidence interval={:0.3f}'.format(np.mean(cv_err_l1), np.std(cv_err_l1)/np.sqrt(10), np.std(cv_err_l1)/np.sqrt(10)*1.96))\n"
      ],
      "metadata": {
        "id": "FWxf-Qj0UA7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}